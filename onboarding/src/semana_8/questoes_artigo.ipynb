{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNojUJ8fI7KuHKWMgWDTMkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luana-lrb/LIPAI_Python/blob/main/onboarding/src/semana_8/questoes_artigo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Questões sobre o artigo científico**"
      ],
      "metadata": {
        "id": "Zk7yAilkSNsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Baseado no artigo de \"Handwritten Digit Recognition with a Back-Propagation Network:\", publicado por LeCun e colaboradores em 1989:\n",
        "  [Handwritten Digit Recognition with a Back-Propagation Network]( https://file.notion.so/f/f/993fc562-485f-4cfa-8330-f0c5084f7804/dd105614-14a4-417b-b203-f5324c248aa7/1989_-_Handwritten_Digit_Recognition_with_a_Back-Propagation_Network.pdf?table=block&id=2167c03f-8b25-80bb-8b0b-fab7aa04507d&spaceId=993fc562-485f-4cfa-8330-f0c5084f7804&expirationTimestamp=1759291200000&signature=vGquFNcbU8YzXgoweK8dy-AeppfAqzFIcMy51-CfClI&downloadName=1989+-+Handwritten+Digit+Recognition+with+a+Back-Propagation+Network.pdf)"
      ],
      "metadata": {
        "id": "-ycUxN32SNSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introdução (Seções 1 e 2)**"
      ],
      "metadata": {
        "id": "T80I8eqrT2x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Por que os autores escolheram dígitos manuscritos como aplicação?"
      ],
      "metadata": {
        "id": "uqnv7PC5UFMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Escolheram porque é uma tarefa de visão computacional relativamente simples (entrada binária preto/branco, dígitos bem separados do fundo, apenas 10 categorias de saída), e apesar da simplicidade, o problema possui complexidade e regularidade suficientes para ser desafiador, lidando com objetos em espaço bidimensional real, tendo grande valor prático, sendo útil para aplicações reais, além de oferecer um equilíbrio ideal entre simplicidade técnica e relevância prática\n",
        "\n"
      ],
      "metadata": {
        "id": "-iKA6uwPXhhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O que diferencia o método deste artigo dos métodos anteriores?"
      ],
      "metadata": {
        "id": "aMusPcrbUYU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> As principais diferenças são a **alimentação direta com imagens**, recebe imagens brutas como entrada, não vetores de características pré-processados e **menos pré-processamento manual**, o método depende muito mais do aprendizado automático e muito menos de engenharia manual de características. Elimina a necessidade de um estágio grande *e* complexo de pré-processamento que exigiria engenharia detalhada. Demonstrando que redes BP podem lidar diretamente com grandes quantidades de informações de baixo nível.\n",
        "\n"
      ],
      "metadata": {
        "id": "_GEa_vpgYgfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessamento (Seção 3)**"
      ],
      "metadata": {
        "id": "6gKb8ZrwZZzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Por que as imagens precisam ser redimensionadas?"
      ],
      "metadata": {
        "id": "dG6kcAa2tUJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> As imagens precisam ser redimensionadas porque a entrada de uma rede de retropropagação tem tamanho fixo e os dígitos originais têm tamanhos variáveis (tipicamente cerca de 40 por 60 pixels). Portanto, é necessário padronizar todas as imagens para um formato uniforme (16 por 16 pixels) para que a rede possa processá-las, senão a rede não conseguiria receber e processar as imagens de forma consistente.\n",
        "\n"
      ],
      "metadata": {
        "id": "7DshXiRLtcMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Por que a normalização das imagens é importante?"
      ],
      "metadata": {
        "id": "uvcivYy1tYBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> A normalização é importante porque uniformiza o tamanho de todos os caracteres, permitindo que a rede processe entradas consistentes, preservando a proporção (aspect ratio) dos caracteres originais, mantendo suas características visuais importantes. Padroniza a escala dos valores dos pixels (de -1 a 1), facilitando o processo de aprendizado da rede neural com a transformação para níveis de cinza (em vez de manter binário) preservando informações que seriam perdidas no redimensionamento. Para permitir que a rede aprenda padrões independentes do tamanho original dos dígitos.\n",
        "\n"
      ],
      "metadata": {
        "id": "1llKJFWutbsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Arquitetura da Rede (Seção 4)**"
      ],
      "metadata": {
        "id": "xliR2cHex9pL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O que é campo receptivo local e qual sua importância em CNNs?"
      ],
      "metadata": {
        "id": "X_Dw_uf41Y8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Campo receptivo local é a região limitada da imagem de entrada da qual um neurônio recebe suas conexões. No texto, cada unidade conecta-se apenas a uma vizinhança de 5 por 5 pixels, não à imagem inteira.São importantes porque permitem detectar características locais (bordas, cantos, padrões pequenos) que são fundamentais para reconhecimento de formas, refletem o conhecimento prévio de que características visuais importantes são geralmente locais, reduzem drasticamente o número de conexões e parâmetros, tornando o treinamento viável."
      ],
      "metadata": {
        "id": "d7xrUuNv1sas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Como funciona o compartilhamento de pesos? Por que ele é vantajoso?"
      ],
      "metadata": {
        "id": "BmS5Sliu1gNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Funciona de forma que todas as unidades em um mesmo mapa de características são restritas a usar o mesmo conjunto de pesos. Isso significa que o mesmo detector de características é aplicado em todas as posições da imagem (equivalente a uma convolução).\n",
        "\n",
        "> As vantagens são a redução massiva de parâmetros livres, pois um grande número de unidades compartilha os mesmos pesos, reduzindo drasticamente o que precisa ser aprendido, a invariância a translações, logo, se uma característica é útil em uma parte da imagem, será útil em outras partes também, a melhor generalização, ou seja, menos parâmetros significam menor risco de overfitting e a eficiência computacional, o mesmo filtro é reutilizado, permitindo paralelização."
      ],
      "metadata": {
        "id": "Ny9A3pVf3RaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Qual é a função das camadas de subamostragem?"
      ],
      "metadata": {
        "id": "c2k_wDk51lc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> As camadas de subamostragem têm várias funções críticas, **reduzir a resolução espacial**, pois realizam média local e subamostragem de 2 para 1, diminuindo o tamanho dos mapas de características, **introduzir invariância a distorções e translações**, características de nível mais alto não precisam de codificação precisa de localização, tornando a rede mais robusta, **reduzir** a sensibilidade a pequenos deslocamentos, um leve deslocamento ou distorção da entrada tem efeito reduzido na representação, **aumentam o campo receptivo efetivo**, cada unidade em camadas superiores \"vê\" uma região maior da imagem original e elas **criam hierarquia de abstração**, permitindo extrair características de crescente complexidade nas camadas subsequentes."
      ],
      "metadata": {
        "id": "-Ctu1An33Sbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resultados (Seção 5)**"
      ],
      "metadata": {
        "id": "VxQZRpK09CW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quais foram os resultados principais obtidos?"
      ],
      "metadata": {
        "id": "1utjoJaw9ENc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Desempenho de classificação no **conjunto de treinamento**, foi 1,1% de erro e MSE de 0,017, no **conjunto de teste completo** foi 3,4% de erro e MSE de 0,024, sendo que todos os erros ocorreram apenas em caracteres manuscritos (0% de erro nos impressos). Com critério de 5,7% de rejeições necessárias para alcançar 1% de erro no conjunto completo e 9% de rejeições para 1% de erro apenas no conjunto manuscrito. Metade dos erros foram devido à segmentação defeituosa, um quarto devido à atribuição errônea de categorias e o restante devido à imagens ambíguas ou erros sem razão discernível. Com apenas 30 passagens pelo conjunto de treinamento.\n"
      ],
      "metadata": {
        "id": "Ly4a0ixi9Pos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Qual a importância prática do critério de rejeição?"
      ],
      "metadata": {
        "id": "EHmSh3O99LXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> O critério de rejeição é extremamente importante em aplicações práticas por várias razões: **a relevância para aplicações reais**, onde é melhor rejeitar casos duvidosos do que cometer erros e os usuários preferem que o sistema \"peça ajuda\" em casos incertos do que forneça respostas erradas, **o controle de qualidade**, que permite ajustar o trade-off entre precisão e automação e com apenas 5,7% de rejeições, o sistema atinge 1% de erro (muito melhor que os 3,4% sem rejeição) e o sistema pode operar com alta confiança nos casos aceitos, **a viabilidade comercial**, pois os casos rejeitados podem ser processados por humanos ou métodos alternativos e ainda automatiza mais de 90% dos casos com alta precisão, reduzindo drasticamente o trabalho manual necessário, e **o mecanismo de três limiares**, verifica se a classificação tem confiança alta, garante que não há ambiguidade e assegura separação clara entre as duas principais candidatas.\n"
      ],
      "metadata": {
        "id": "tJHcs1HgA11V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusão (Seção 6)**"
      ],
      "metadata": {
        "id": "g-p-UhWEB5wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quais vantagens os autores identificaram ao usar CNNs com aprendizado via backpropagation?"
      ],
      "metadata": {
        "id": "kKSrDCisCKA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Os autores identificaram diversas vantagens importantes: O **pré-processamento mínimo:** A rede pôde ser treinada em representação de baixo nível dos dados (pixels brutos). Não necessita extração elaborada de características manual. Reduz a engenharia manual complexa necessária. A **eficiência de parâmetros:** Muitas conexões, mas relativamente poucos parâmetros livres. Melhor generalização devido ao menor número de parâmetros a aprender. O **tempo de treinamento:** Aprendizado relativamente rápido (apenas 30 épocas).\n",
        "Atribuído à redundância dos dados e às restrições da rede. A **escalabilidade excelente:** Propriedades de escalabilidade muito melhores do que extrapolações de problemas menores sugeriam. Resultados preliminares mostram que o método pode ser estendido a tarefas maiores (caracteres alfanuméricos). A **Implementação prática:** Rede prontamente implementável em hardware comercial (DSP). Desempenho em tempo real: mais de 10 dígitos por segundo. Da câmera à classificação completa.\n"
      ],
      "metadata": {
        "id": "9564PbxTCR2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Por que é importante ter restrições na arquitetura e nos pesos da rede?"
      ],
      "metadata": {
        "id": "2v27-RPuCOwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> As restrições na arquitetura e nos pesos são fundamentais por várias razões: A **Incorporação de conhecimento prévio:** As restrições permitem incorporar conhecimento geométrico sobre a tarefa no sistema. Refletem princípios conhecidos sobre reconhecimento de formas (características locais, invariância espacial). A **Redução de parâmetros livres:** Muitas conexões, mas poucos parâmetros independentes. Compartilhamento de pesos reduz drasticamente o que precisa ser aprendido. A **Melhor generalização:** Menos parâmetros livres = menor risco de overfitting. Rede especializada com entropia reduzida. Aumenta a probabilidade de generalização correta. A **Aprendizado mais rápido**: As restrições contribuíram para o tempo de aprendizado relativamente curto. Menos parâmetros para otimizar acelera a convergência. A **Eficiência computacional:** Restrições como campos receptivos locais e compartilhamento de pesos tornam a rede mais eficiente. E as **Invariâncias úteis:** Restrições específicas (como compartilhamento de pesos) introduzem invariâncias desejáveis (translação, pequenas distorções)."
      ],
      "metadata": {
        "id": "AT3S2QNgDPgu"
      }
    }
  ]
}